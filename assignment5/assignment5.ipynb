{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e2833ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: scipy in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to install the required libraries\n",
    "%pip install numpy matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7988b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31962ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enables inline matplotib graphs\n",
    "%matplotlib inline\n",
    "# Comment the line above and uncomment the lines below to have interactive plots\n",
    "# WARN: may cause dependency issues\n",
    "# %matplotlib qt5\n",
    "# %pip install PyQt5\n",
    "# plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277670c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/m.manso/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages (from gymnasium) (0.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gymnasium\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a37715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a population randomly based on the population size and dimensions\n",
    "def initialization(population_size, num_dimensions):\n",
    "    \"\"\"\n",
    "    Initialize the starting population with random individuals.\n",
    "    Each gene of an individual corresponds to a point on a dimension in the function\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.random.uniform(-1, 1, (population_size, num_dimensions)) # generate the population using the size and dimensions as an ndarray\n",
    "\n",
    "\n",
    "    return x #return population\n",
    "\n",
    "\n",
    "# Implement the evaluation function that can evaluate all the solutions in a given population.\n",
    "def evaluation(x, objective_function):\n",
    "    \"\"\"Evaluate the fitness of the population members\"\"\"\n",
    "\n",
    "    fitness = np.array([objective_function(individual) for individual in x]) \n",
    "\n",
    "    return fitness\n",
    "\n",
    "\n",
    "# Implement the crossover operator by choosing a suitable method. For inspiration, take a look at the lecture slides\n",
    "def crossover(x_parents, p_crossover):\n",
    "    \"\"\"Perform crossover to create offsprings.\"\"\"\n",
    "\n",
    "    if np.random.rand() <= p_crossover: #only use crossover when the a random number is lower then the crossover chance\n",
    "      parent1, parent2 = x_parents\n",
    "\n",
    "      n = np.shape(x_parents)[1] #define the dimensions of a individual based on the second parent\n",
    "\n",
    "      crossover_point = np.random.randint(1,n) # generate a random point in the range from 1 till the dimensions\n",
    "\n",
    "      #create the children based on crossover point with one half being one parent and the other being another parent\n",
    "      child1 = np.hstack([parent1[:crossover_point], parent2[crossover_point:]])\n",
    "      child2 = np.hstack([parent2[crossover_point:], parent1[:crossover_point]])\n",
    "      offspring = [child1, child2] #return children\n",
    "    else:\n",
    "      parent1, parent2 = x_parents\n",
    "      offspring = [parent1, parent2] # if no crossover happens then the parents are returned\n",
    "\n",
    "\n",
    "    return offspring\n",
    "\n",
    "\n",
    "# Implement the crossover operator by choosing a suitable method. For inspiration, take a look at the lecture slides\n",
    "def mutation(x, mutation_rate, population_size, num_dimensions):\n",
    "    \"\"\"Apply mutation to an individual.\"\"\"\n",
    "\n",
    "    if np.random.rand() <= mutation_rate: #if the random number is under the chance of having mutation then perform the mutation\n",
    "      x = np.random.uniform(-1, 1, num_dimensions) #create a bit of noise which displaces the individuals genes in a radius of 5\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def parent_selection(x, f):\n",
    "    \"\"\"Select parents for the next generation\"\"\"\n",
    "\n",
    "    fitness_sum = np.sum(f) # sum the fitnesses\n",
    "\n",
    "    probability = f / fitness_sum #normalize the fitnesses for every individual to get a chance\n",
    "\n",
    "    indice = [i for i in range(len(x))] #give each individual a id/number for the index\n",
    "\n",
    "    numbers = np.random.choice(indice, size=2, p=probability, replace=False) #choose out of the id's\n",
    "\n",
    "    #numbers = np.argsort(f)[:2]\n",
    "    x_parents = [x[i] for i in numbers] #search based on the random id/number\n",
    "    f_parents = [f[i] for i in numbers]\n",
    "\n",
    "    return x_parents, f_parents\n",
    "\n",
    "\n",
    "def survivor_selection(x, f, x_offspring, f_offspring):\n",
    "    \"\"\"Select the survivors, for the population of the next generation\"\"\"\n",
    "\n",
    "    limit = len(x) #see the maximum carry case of the population\n",
    "\n",
    "    combined_x = np.concatenate([x, x_offspring]) #combine the individuals in one list\n",
    "    combined_f = np.concatenate([f, f_offspring]) #cobmine all the fitnesses in one list\n",
    "\n",
    "    begin = len(combined_f) - limit\n",
    "    index = np.argsort(combined_f)[begin:] #sort the fitnesses from low to high and then only go to the maximum carry limit\n",
    "\n",
    "    #return a list of those individuals with the best fitnesses\n",
    "    x = [combined_x[i] for i in index]\n",
    "    f = [combined_f[i] for i in index]\n",
    "\n",
    "    return x, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd755c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp = 4 # Number of input neurons\n",
    "hid = 16 # Number of hidden neurons\n",
    "out = 2 # Nubmer of output neurons\n",
    "\n",
    "#Open AI gym environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# CartPole evaluation function\n",
    "def cartpole(x):\n",
    "\n",
    "    ###########\n",
    "    # PLEASE FILL IN\n",
    "    # Hint: x is an individual in evolutionary algorithms and needs to map to the connection weights of ANNs\n",
    "    amount_w1 = inp * hid\n",
    "    amount_w2 = hid * out\n",
    "\n",
    "    w1 = np.array(x[:amount_w1]).reshape(inp, hid) #weights for the first layer\n",
    "    w2 = np.array(x[amount_w1:]).reshape(hid, out) #weights for the second layer\n",
    "    #########\n",
    "\n",
    "    # Reset environment\n",
    "    observation, info = env.reset(seed = 0)\n",
    "\n",
    "    rew = 0 # Initial reward\n",
    "    step = 0; #step counter\n",
    "    done = False\n",
    "    maxStep = 1000  # maximum number of steps\n",
    "    while not done and step<1000:\n",
    "      ###################\n",
    "      # PLEASE FILL IN\n",
    "      # Hint: Provide input to ANN and find the output to be the action\n",
    "      #get the dot product of the weights and the observation which helps get h and apply tanh activation on it\n",
    "      h = np.tanh(np.dot(observation, w1))\n",
    "      output = np.dot(h, w2)\n",
    "      action = np.argmax(output) #this will give the highest value position for the action value\n",
    "\n",
    "      observation, reward, done, tr, info = env.step(action)\n",
    "      step+=1 # step counter\n",
    "      rew = rew + reward # after each step increment reward\n",
    "\n",
    "    env.close()\n",
    "    return np.minimum(maxStep, rew) # return the reward or maxStep (if maxStep < 1000, this means that pole fell)\n",
    "\n",
    "\n",
    "\n",
    "# CartPole evaluation function with video recording\n",
    "def cartpole_record_video(x):\n",
    "    tmp_env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "    # Video recording function - be sure to check the folder path - you should see the video here:content/video/cartpole\n",
    "    env = gym.wrappers.RecordVideo(env=tmp_env, video_folder=\".\", name_prefix=\"cartpole\")\n",
    "\n",
    "    ###########\n",
    "    # PLEASE FILL IN\n",
    "    # Hint: x is an individual in evolutionary algorithms and needs to map to the connection weights of ANNs\n",
    "\n",
    "    #########\n",
    "    amount_w1 = inp * hid\n",
    "    amount_w2 = hid * out\n",
    "\n",
    "    w1 = np.array(x[:amount_w1]).reshape(inp, hid)\n",
    "    w2 = np.array(x[amount_w1:]).reshape(hid, out)\n",
    "    # Reset environment\n",
    "    observation, info = env.reset(seed = 0)\n",
    "\n",
    "    #env.start_video_recorder()\n",
    "\n",
    "\n",
    "    rew = 0 # Initial reward\n",
    "    step = 0; #step counter\n",
    "    done = False\n",
    "    maxStep = 1000  # maximum number of steps\n",
    "    while not done and step<1000: # run nStep number of time\n",
    "\n",
    "      ###################\n",
    "      # PLEASE FILL IN\n",
    "      # Hint: Provide input to ANN and find the output to be the action\n",
    "      # action = ?\n",
    "      h = np.tanh(np.dot(observation, w1))\n",
    "      output = np.dot(h, w2)\n",
    "      action = np.argmax(output)\n",
    "\n",
    "      # action should be provided based on the output of the artifial neural network\n",
    "      observation, reward, done, tr, info = env.step(action)\n",
    "      step+=1 # step counter\n",
    "      rew = rew + reward # after each step increment reward\n",
    "      #env.render()\n",
    "\n",
    "    #env.close_video_recorder()\n",
    "    env.close()\n",
    "    return np.minimum(maxStep, rew) # return the reward or maxStep (if maxStep < 1000, this means that pole fell)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CartPole evaluation function for visualizing the cartpole environment\n",
    "def cartpole_visualize(x):\n",
    "    tmp_env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "    ###########\n",
    "    # PLEASE FILL IN\n",
    "    # Hint: x is an individual in evolutionary algorithms and needs to map to the connection weights of ANNs\n",
    "    amount_w1 = inp * hid\n",
    "    amount_w2 = hid * out\n",
    "\n",
    "    w1 = np.array(x[:amount_w1]).reshape(inp, hid)\n",
    "    w2 = np.array(x[amount_w1:]).reshape(hid, out)\n",
    "    #########\n",
    "\n",
    "    # Reset environment\n",
    "    observation, info = tmp_env.reset(seed = 0)\n",
    "\n",
    "    rew = 0 # Initial reward\n",
    "    step = 0; #step counter\n",
    "    done = False\n",
    "    maxStep = 1000  # maximum number of steps\n",
    "    while not done and step<1000: # run nStep number of time\n",
    "\n",
    "      ###################\n",
    "      # PLEASE FILL IN\n",
    "      # Hint: Provide input to ANN and find the output to be the action\n",
    "      # action = ?\n",
    "      h = np.tanh(np.dot(observation, w1))\n",
    "      output = np.dot(h, w2)\n",
    "      action = np.argmax(output)\n",
    "\n",
    "      # action should be provided based on the output of the artifial neural network\n",
    "      observation, reward, done, tr, info = tmp_env.step(action)\n",
    "      step+=1 # step counter\n",
    "      rew = rew + reward # after each step increment reward\n",
    "      tmp_env.render()\n",
    "\n",
    "    tmp_env.close()\n",
    "    return np.minimum(maxStep, rew) # return the reward or maxStep (if maxStep < 1000, this means that pole fell)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Implement your Evolutionary Algorithm to find the ANN weigths that can balance the CartPole\n",
    "# Feel free to add any functions, such as initialization, crossover, etc.. to make it work!\n",
    "def ea(\n",
    "    # hyperparameters of the algorithm\n",
    "    population_size,\n",
    "    max_fit_evals,  # Maximum number of evaluations\n",
    "    p_crossover,  # Probability of performing crossover operator\n",
    "    m_rate,  # mutation rate\n",
    "    objective_function,  # objective function to be minimized\n",
    "):\n",
    "    # Calculate the maximum number of generations\n",
    "    # Maximum number of function evaluations should be the same independent of the population size\n",
    "    max_generations = int(max_fit_evals / population_size)  # DO NOT CHANGE\n",
    "\n",
    "\n",
    "\n",
    "    ################################################################\n",
    "    # PLEASE FILL IN\n",
    "    dim = (inp * hid) + (hid * out) #calculate the dimension of the individual\n",
    "    x = initialization(population_size, dim) #initialize the population\n",
    "    f = evaluation(x, objective_function) #evaluate the base fitnesses of the initial population\n",
    "\n",
    "    ################################################################\n",
    "\n",
    "    # Find the best individual and append to a list to keep track in each generation\n",
    "    idx = np.argmax(f)\n",
    "    x_best = [x[idx]]\n",
    "    f_best = [f[idx]]\n",
    "\n",
    "    # Loop over the generations\n",
    "    for _ in range(max_generations - 1):\n",
    "        # Perform the EA steps\n",
    "\n",
    "        ################################################################\n",
    "        x_parents, f_parents = parent_selection(x, f) #select the parent for the new generation\n",
    "\n",
    "        x_offspring = []\n",
    "        f_offspring = []\n",
    "\n",
    "        #try crossover and mutation population times\n",
    "        for i in range(len(x)):\n",
    "          children = crossover(x_parents, p_crossover) #perform crossover and get the children\n",
    "\n",
    "          for child in children:\n",
    "            mutated_child = mutation(child, m_rate, population_size, dim) #for child see if the dna of the child mutates\n",
    "            x_offspring.append(mutated_child) #append the mutated child to the offspring list\n",
    "            f_offspring.append(objective_function(mutated_child))#get respective fitnesses of the children\n",
    "\n",
    "\n",
    "\n",
    "        x, f = survivor_selection(x, f, x_offspring, f_offspring) #see which individuals make the next generation\n",
    "        ################################################################\n",
    "\n",
    "\n",
    "        # Find the best individual in current generation and add to the list\n",
    "        idx = np.argmax(f)\n",
    "        xi_best = x[idx]\n",
    "        fi_best = f[idx]\n",
    "        if fi_best < f_best[-1]:\n",
    "            x_best.append(xi_best)\n",
    "            f_best.append(fi_best)\n",
    "        else:\n",
    "            x_best.append(x_best[-1])\n",
    "            f_best.append(f_best[-1])\n",
    "\n",
    "\n",
    "    return x_best, f_best  # return the best solution (ANN weights) and the fitness in each generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a146c8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN parameters found: [ 0.34281925  0.61145455 -0.73317463  0.90947345 -0.75475022 -0.63321926\n",
      "  0.28062663 -0.24771705  0.30083323 -0.07937986  0.38522915 -0.74651823\n",
      "  0.12989417  0.46584944 -0.08244045  0.34231504  0.33249934  0.63651216\n",
      " -0.99648917 -0.2197327  -0.33384208 -0.58409354 -0.4216591   0.78345457\n",
      " -0.42119617  0.6428173  -0.70293759  0.09337579 -0.89253395  0.45766361\n",
      " -0.32920861 -0.80739806 -0.27565483 -0.81454927  0.16081309  0.25669763\n",
      "  0.73772384 -0.22705435 -0.71123677 -0.70517935  0.91036617  0.07388429\n",
      " -0.74984373 -0.32642801  0.3217709   0.41728684  0.31214697 -0.96640051\n",
      "  0.84337426  0.80389228 -0.51953603 -0.80787881 -0.55239542 -0.66315108\n",
      "  0.85940756 -0.47500766 -0.59293371  0.32436935  0.0798057  -0.67514034\n",
      "  0.5123652   0.61975136 -0.42733154  0.92294339  0.55498573  0.40836982\n",
      " -0.22004943 -0.72227212  0.56898731  0.43626913  0.84894362 -0.59388842\n",
      " -0.09020666 -0.53375184  0.38399057 -0.61558291  0.33872009 -0.6027416\n",
      "  0.76336654 -0.74537907 -0.34577845  0.76352477  0.18733311  0.20202043\n",
      "  0.55685335  0.47668488 -0.88153584 -0.90776625 -0.56820764  0.45574036\n",
      " -0.55828038  0.87117407 -0.74248356 -0.70051287  0.50904587 -0.87526372]\n",
      "Best fitnes found: 1000.0\n"
     ]
    },
    {
     "ename": "DependencyNotInstalled",
     "evalue": "moviepy is not installed, run `pip install \"gymnasium[other]\"`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages/gymnasium/utils/save_video.py:13\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImageSequenceClip\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageSequenceClip\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moviepy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Evaluate your ANN weights again and record the video\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f_best[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m---> 20\u001b[0m   \u001b[43mcartpole_record_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_best\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m   \u001b[38;5;66;03m#  cartpole_visualize(x_best[-1] )\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best fitness 1000 was not found, try again!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 51\u001b[0m, in \u001b[0;36mcartpole_record_video\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     48\u001b[0m tmp_env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCartPole-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Video recording function - be sure to check the folder path - you should see the video here:content/video/cartpole\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrappers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecordVideo\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcartpole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m###########\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# PLEASE FILL IN\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Hint: x is an individual in evolutionary algorithms and needs to map to the connection weights of ANNs\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#########\u001b[39;00m\n\u001b[1;32m     58\u001b[0m amount_w1 \u001b[38;5;241m=\u001b[39m inp \u001b[38;5;241m*\u001b[39m hid\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages/gymnasium/wrappers/rendering.py:285\u001b[0m, in \u001b[0;36mRecordVideo.__init__\u001b[0;34m(self, env, video_folder, episode_trigger, step_trigger, video_length, name_prefix, fps, disable_logger, gc_trigger)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRender mode is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which is incompatible with RecordVideo.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialize your environment with a render_mode that returns an image, such as rgb_array.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode_trigger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_trigger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msave_video\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capped_cubic_video_schedule\n\u001b[1;32m    287\u001b[0m     episode_trigger \u001b[38;5;241m=\u001b[39m capped_cubic_video_schedule\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_trigger \u001b[38;5;241m=\u001b[39m episode_trigger\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/text_mining1/lib/python3.12/site-packages/gymnasium/utils/save_video.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImageSequenceClip\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageSequenceClip\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m gym\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mDependencyNotInstalled(\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoviepy is not installed, run `pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgymnasium[other]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcapped_cubic_video_schedule\u001b[39m(episode_id: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"The default episode trigger.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    This function will trigger recordings at the episode indices :math:`\\{0, 1, 4, 8, 27, ..., k^3, ..., 729, 1000, 2000, 3000, ...\\}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m        If to apply a video schedule number\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: moviepy is not installed, run `pip install \"gymnasium[other]\"`"
     ]
    }
   ],
   "source": [
    "# Dummy parameters, please add or remove based on your implementation\n",
    "kwargs = {\n",
    "    \"population_size\": 20,\n",
    "    \"max_fit_evals\": 1000,  # maximum number of fitness evaluations\n",
    "    \"p_crossover\": 0.9,  # crossover probability\n",
    "    \"m_rate\": 0.1,  # mutation rate\n",
    "    \"objective_function\": cartpole,\n",
    "}\n",
    "# Run your algorithm once and find the best ANN weigths found\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "x_best, f_best = ea(**kwargs)\n",
    "\n",
    "\n",
    "# Print the best ANN weigths found and best fitness\n",
    "print(\"Best ANN parameters found:\",x_best[-1])\n",
    "print(\"Best fitnes found:\",f_best[-1])\n",
    "\n",
    "# Evaluate your ANN weights again and record the video\n",
    "if f_best[-1] >= 1000:\n",
    "  cartpole_record_video(x_best[-1] )\n",
    "  #  cartpole_visualize(x_best[-1] )\n",
    "else:\n",
    "  print(\"The best fitness 1000 was not found, try again!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8ed5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Best fitnes found: 1000.0\n",
      "Run 2\n",
      "Best fitnes found: 193.0\n",
      "Run 3\n",
      "Best fitnes found: 43.0\n",
      "Run 4\n",
      "Best fitnes found: 108.0\n",
      "Run 5\n",
      "Best fitnes found: 172.0\n",
      "Run 6\n",
      "Best fitnes found: 1000.0\n",
      "Run 7\n",
      "Best fitnes found: 221.0\n",
      "Run 8\n",
      "Best fitnes found: 446.0\n",
      "Run 9\n",
      "Best fitnes found: 180.0\n",
      "Run 10\n",
      "Best fitnes found: 138.0\n"
     ]
    }
   ],
   "source": [
    "runs = 10\n",
    "best_xs = []\n",
    "best_fs = []\n",
    "\n",
    "kwargs = {\n",
    "    \"population_size\": 20,\n",
    "    \"max_fit_evals\": 1000,  # maximum number of fitness evaluations\n",
    "    \"p_crossover\": 0.9,  # crossover probability\n",
    "    \"m_rate\": 0.1,  # mutation rate\n",
    "    \"objective_function\": cartpole,\n",
    "}\n",
    "\n",
    "for i in range(runs):\n",
    "  x_best, f_best = ea(**kwargs)\n",
    "  best_xs.append(x_best)\n",
    "  best_fs.append(f_best)\n",
    "  print(f\"Run {i+1}\")\n",
    "  print(\"Best fitnes found:\",f_best[-1])\n",
    "\n",
    "average_fs = np.mean(best_fs, axis=0)\n",
    "std_fs = np.std(best_fs, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb1431f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(best_fs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ece649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " experiment average: 350.1\n",
      " experiment std: 339.68322007423325\n"
     ]
    }
   ],
   "source": [
    "print(f\" experiment average: {average_fs[1]}\")\n",
    "print(f\" experiment std: {std_fs[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_mining1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
